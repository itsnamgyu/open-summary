The paper proposes leveraging large language models (LLMs) for zero-shot reasoning about crimes using textual descriptions from surveillance videos. It highlights the need for advanced techniques to detect and surface potential crime cases due to the overwhelming amount of data. The challenges of automatically detecting crime are attributed to the diverse ways crimes can be committed and the power law distribution of losses caused by crime. The paper introduces the use of GPT-4 for zero-shot crime detection and evaluates its performance using manually created descriptions of surveillance videos. It identifies limitations in automatic video description generation and provides a dataset of textual descriptions from real-world surveillance videos. Furthermore, the paper discusses the shortcomings of existing approaches and explores different methods, including using multimodal models, to reason about crime. The results show that GPT-4 can accurately detect crimes with high-quality human-generated descriptions but performs poorly with automatically generated ones. The paper concludes by highlighting the challenges, such as the lack of objective detail in video-to-text conversion, the inability of object tracking algorithms to maintain identities, and the absence of weapons in curated object detection datasets. Overall, the study emphasizes the need for further research to overcome the limitations of current approaches and achieve fully automated crime detection.
